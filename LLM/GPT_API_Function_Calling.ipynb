{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuMB5xs8loWo"
      },
      "source": [
        "# GPT API: Function Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAHFT4NNusOH"
      },
      "source": [
        "Unfortunately, since the GPT 3.5 and 4 models are trained with data from June-September 2021 and December 2023 and before, they cannot know information that emerges or is discovered after June-September 2021 or December 2023. They are also inadequate for solving complex math problems. In this case, our models can be used by calling the function we define for the model to return more consistent and accurate results on topics they are unfamiliar or weak in.\n",
        "\n",
        "For example, let's consider that the calculation of body mass index was discovered after April 2023, or the models are very bad at calculating body mass index. Let's create a function below for the model to calculate BMI correctly and then see how we call this function in GPT models.\n",
        "\n",
        "Function calling is also very useful for pulling the data we want from a text. We will see an example in the Langchain tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WduIsM2MmESY",
        "outputId": "22425179-b467-4d60-e23a-1d0c8dea9533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdFOjKXLFj0z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Axunp8gstn"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFQgD_qDlJcw"
      },
      "outputs": [],
      "source": [
        "def body_mass_index(height,  weight):\n",
        "  \"calculate the body mass index\"\n",
        "  b_m_i=weight/(height*height)\n",
        "\n",
        "  return f\"The body mass index is about {b_m_i:.2f}\"\n",
        "\n",
        "# First, we define our function to calculate the body mass index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBz32oUBlJkW"
      },
      "outputs": [],
      "source": [
        "body_mass_index_func = {\n",
        "    \"name\": \"body_mass_index\",\n",
        "    \"description\": \"Calculates the body mass index.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"height\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"person's height in meters\"\n",
        "            },\n",
        "            \"weight\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"person's weight in kilograms\"\n",
        "            }\n",
        "\n",
        "        },\n",
        "        \"required\": [\"height\",  \"weight\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# We define the function name, description (intended use), function parameters and type as shown above. \n",
        "# The most important part here is the description. Because it is based on these function descriptions that the model decides whether to call a function or not.\n",
        "# Also, based on the parameter descriptions, the model can select the relevant parameters from the text.\n",
        "\n",
        "# If the question is semantically very close to the function description, the model will call that function. However, if the function description is poorly done or incomplete, the model will not call the function.\n",
        "\n",
        "# After the model calls the function, it is important to have well-defined parameter descriptions to select the correct parameters from the text.\n",
        "# If the parameter descriptions are poorly done or missing, the model will not be able to select the correct parameters from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As0YG5EtJV6i",
        "outputId": "5e18844f-7104-4c59-f783-e58b19d87bf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(body_mass_index_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT4bpFGBlJqV",
        "outputId": "a7f9aca0-e596-4e4d-8419-7460344dd6bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Gt5ubEnkTvt0nAEEDrCn1J3CmVgI', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"height\":1.8,\"weight\":80}', name='body_mass_index'), tool_calls=None))], created=1713812058, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=21, prompt_tokens=87, total_tokens=108))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"What is the body mass index of a person who is 1800 mm tall and weight 80000 grams?\"\n",
        "\n",
        "res = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    functions=[body_mass_index_func],\n",
        "    function_call=\"auto\"\n",
        ")\n",
        "res\n",
        "\n",
        "# Set the 'functions' parameter to 'body_mass_index_func'.\n",
        "\n",
        "# Set the 'function_call' parameter to 'auto'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WGygIB04B-IS",
        "outputId": "59fa5d3a-2c14-4884-84f8-90f2850fae91"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"height\":1.8,\"weight\":80}'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.choices[0].message.function_call.arguments\n",
        "# We extract the selected parameters from the Prompt text.\n",
        "\n",
        "# As you can see, our output is in JSON format (string).\n",
        "# In Python, we cannot use JSON format data directly. Therefore, we need to convert the data to dictionary format using the json.loads() function\n",
        "# In Python we can use data in JSON format.\n",
        "# Once the data is converted to dictionary format, we can easily extract height and weight information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-1Hb8HdlJwG",
        "outputId": "be2fe1d5-69b2-4312-aa99-a4159f6869f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "body_mass_index\n",
            "{'height': 1.8, 'weight': 80}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "name = res.choices[0].message.function_call.name\n",
        "arguments = json.loads(res.choices[0].message.function_call.arguments) # Use the json.loads() function to translate a JSON string into a dictionary.\n",
        "                                                                       # This function translates a JSON string into a dictionary.\n",
        "print(name)\n",
        "print(arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcvW2ZmJqASl",
        "outputId": "b0d0386f-8068-4582-d90f-cd6f36d0fb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8\n",
            "80\n"
          ]
        }
      ],
      "source": [
        "print(arguments[\"height\"])\n",
        "print(arguments[\"weight\"])\n",
        "\n",
        "# We were able to easily capture height and weight information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2KoVaY7rqk3c",
        "outputId": "2b7ee38e-8368-4a3a-e29f-08b39132a095"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The body mass index is about 24.69'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "body_mass_index(arguments[\"height\"],  arguments[\"weight\"])\n",
        "\n",
        "# When I write the parameters into the function we defined, it returns the output I want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0jvDck_qAbl"
      },
      "outputs": [],
      "source": [
        "def run_conversation(prompt):\n",
        "\n",
        "    response = client.chat.completions.create(model='gpt-3.5-turbo',\n",
        "                                              messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                                              functions=[body_mass_index_func],\n",
        "                                              function_call=\"auto\")\n",
        "\n",
        "\n",
        "    # Step 1, check if the model wants to call a function (function_calling)\n",
        "    if  response.choices[0].finish_reason == \"function_call\":\n",
        "        # convert json string to dictionary\n",
        "        arguments = json.loads(response.choices[0].message.function_call.arguments)\n",
        "\n",
        "        # Step 2, call the function and assign it to a variable\n",
        "        function_response = body_mass_index(arguments[\"height\"],\n",
        "                                            arguments[\"weight\"])\n",
        "\n",
        "        return function_response # return the result of the function\n",
        "    return response.choices[0].message.content # if the function is not called. Return the kenid response of chatgpt.\n",
        "\n",
        "\n",
        "# If the model returns \"function_call\" as \"finish_reason\" after the text we give to the run_conversation function,\n",
        "# will give its answers via the body_mass_index function. Otherwise the model will give its answers in its own way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V4hKu4BUqAjD",
        "outputId": "e48e39ef-f3f5-4be5-aed1-401b87b23d2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The body mass index is about 24.69'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_conversation(\"What is the body mass index of a person who is 1800 mm tall and weight 80000 grams?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vbGo6reupqcO",
        "outputId": "c440d10b-4c1e-4dbe-94ad-b64e577a7276"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The capital of Spain is Madrid.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_conversation(\"What is the Capital of Spain?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ-DZ1c7xuYn"
      },
      "source": [
        "END OF THE PROJECT"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
