{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT API Fine Tuning for Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4VmEGHIJY35"
      },
      "source": [
        "Try chatgpt for your task before fine-tuning. If chatgpt is not enough, then fine-tune it. Do not forget that chat-gpt may be sufficient for most simple tasks.\n",
        "\n",
        "To fine-tune the GPT-3.5 model, you need to convert each observation in your data to the following message template (Jsonline Format):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pMzh-puJgHY"
      },
      "outputs": [],
      "source": [
        "# \"\"\"{'messages': [{'role': 'system', 'content': 'Given a text, provide the following fields in a JSON format, where applicable:\\\n",
        "#                                              'person (only name/surname)', 'time (week, month, summer etc.)', 'currency (USD, EURO etc.)',\\\n",
        "#                                               and 'place (country, city etc.)'.'},\n",
        "#                  {'role': 'user', 'content': 'The White House is located in Washington, D.C.'},\n",
        "#                  {'role': 'assistant', 'content': \"{'Person': 'null', 'Time': 'null', 'Currency': 'null', 'Place': 'Washington, D.C.'}\"}]}\"\"\"\n",
        "\n",
        "# system: the instructions you give to the model.\n",
        "# user: the feature/independent variable/text of each observation in your data (X)\n",
        "# assistant: the dependent variable/target/label of each observation in your data (y)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCEPg5weDWJR",
        "outputId": "9886acff-bc1a-4c6e-b62a-682059cfbf1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MdfZxyAmvig",
        "outputId": "74f2fe66-8f5c-4bdb-d7b6-020a6bc9bfc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I16ivpcrDto6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYGy7Msa_tY1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PKcnVGQmgTp"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eMrh3BrLfzf"
      },
      "source": [
        "We're getting 20 observations ready for NER fine tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1e-9iYwl7sF"
      },
      "outputs": [],
      "source": [
        "prompt= [\"After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.\",\n",
        "         \"Despite the fact that I had saved up 100.000 USD, I still found it difficult to afford a house in the city.\",\n",
        "         \"When I was a child, my grandparents would take me on long walks through the countryside, and those memories are still some of my most cherished.\",\n",
        "         \"After years of working in the corporate world, I decided to start my own business, and I've never looked back.\",\n",
        "         \"The ancient ruins we visited in Rome were so awe-inspiring that I found myself speechless.\",\n",
        "         \"Despite the fact that I had been practicing for months, my piano recital was a disaster, and I was humiliated.\",\n",
        "         \"When she traveled to Thailand, Mary was amazed by the beauty and serenity of the Buddhist temples.\",\n",
        "         \"My grandmother's estate, which had been passed down through several generations of our family, was the site of many cherished family gatherings.\",\n",
        "         \"When I was a student, I spent a semester studying abroad in France, and it was one of the most enriching experiences of my life.\",\n",
        "         \"After my grandfather passed away, my family and I spent weeks going through his belongings and reminiscing about his life.\",\n",
        "         \"The White House is located in Washington, D.C.\",\n",
        "         \"I need to exchange dollars for euros before I travel to Europe.\",\n",
        "         \"The exchange rate between the pound and the euro is favorable.\",\n",
        "         \"As a child, I used to spend my summers at my grandparents' farm, and those days are some of my most cherished memories.\",\n",
        "         \"After years of working for a multinational corporation, I decided to quit my job and travel the World.\",\n",
        "         \"My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.\",\n",
        "         \"When I was in college, I spent a semester studying abroad in China, and it was an eye-opening experience.\",\n",
        "         \"My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.\",\n",
        "         \"My parents own a small motel in a charming seaside town, and they've been running it for over 20 years.\",\n",
        "         \"Johnson and I decided to take a road trip across the United States during the summer after we graduated from college.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSIpljkUJEdr"
      },
      "outputs": [],
      "source": [
        "# You can edit the output however you like. We wanted the output to be in dictionary format, so we formatted it this way.\n",
        "\n",
        "target= [{\"Person\": \"John Wick\", \"Time\": \"several months\", \"Currency\": \"null\", \"Place\": \"Spain\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"USD\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"years\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Rome\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"months\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"Mary\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Thailand\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"semester\", \"Currency\": \"null\", \"Place\": \"France\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"weeks\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Washington, D.C.\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": [\"dollars\", \"euros\"], \"Place\": \"Europe\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": [\"pound\", \"euro\"], \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": [\"summers\", \"those days\"], \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"years\", \"Currency\": \"null\", \"Place\": \"World\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"semester\", \"Currency\": \"null\", \"Place\": \"China\"},\n",
        "         {\"Person\": \"null\", \"Time\": [\"years\", \"summer\"], \"Currency\": \"null\", \"Place\": \"South America\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"over 20 years\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"Johnson\", \"Time\": \"summer\", \"Currency\": \"null\", \"Place\": \"United States\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "CYbO8k2ArW1B",
        "outputId": "dd94a673-9419-4e7c-c1db-5cf5463bcdcd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.\",\n          \"My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.\",\n          \"My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d44a8262-51c4-4122-9a21-98c45f6d753f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After spending several months studying abroad ...</td>\n",
              "      <td>{'Person': 'John Wick', 'Time': 'several month...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Despite the fact that I had saved up 100.000 U...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When I was a child, my grandparents would take...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After years of working in the corporate world,...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'years', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The ancient ruins we visited in Rome were so a...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Despite the fact that I had been practicing fo...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'months', 'Currency...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>When she traveled to Thailand, Mary was amazed...</td>\n",
              "      <td>{'Person': 'Mary', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My grandmother's estate, which had been passed...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When I was a student, I spent a semester study...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'semester', 'Curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>After my grandfather passed away, my family an...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'weeks', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The White House is located in Washington, D.C.</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I need to exchange dollars for euros before I ...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The exchange rate between the pound and the eu...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>As a child, I used to spend my summers at my g...</td>\n",
              "      <td>{'Person': 'null', 'Time': ['summers', 'those ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>After years of working for a multinational cor...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'years', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>My great-grandfather fought in World War II, a...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When I was in college, I spent a semester stud...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'semester', 'Curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>My best friend and I have been planning a trip...</td>\n",
              "      <td>{'Person': 'null', 'Time': ['years', 'summer']...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>My parents own a small motel in a charming sea...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'over 20 years', 'C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Johnson and I decided to take a road trip acro...</td>\n",
              "      <td>{'Person': 'Johnson', 'Time': 'summer', 'Curre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44a8262-51c4-4122-9a21-98c45f6d753f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d44a8262-51c4-4122-9a21-98c45f6d753f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d44a8262-51c4-4122-9a21-98c45f6d753f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e71dcb2-7faa-4dc2-90d7-f115c7db52a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e71dcb2-7faa-4dc2-90d7-f115c7db52a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e71dcb2-7faa-4dc2-90d7-f115c7db52a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cc90f54a-39ab-421d-90ba-2a1168a556e2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cc90f54a-39ab-421d-90ba-2a1168a556e2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 text  \\\n",
              "0   After spending several months studying abroad ...   \n",
              "1   Despite the fact that I had saved up 100.000 U...   \n",
              "2   When I was a child, my grandparents would take...   \n",
              "3   After years of working in the corporate world,...   \n",
              "4   The ancient ruins we visited in Rome were so a...   \n",
              "5   Despite the fact that I had been practicing fo...   \n",
              "6   When she traveled to Thailand, Mary was amazed...   \n",
              "7   My grandmother's estate, which had been passed...   \n",
              "8   When I was a student, I spent a semester study...   \n",
              "9   After my grandfather passed away, my family an...   \n",
              "10     The White House is located in Washington, D.C.   \n",
              "11  I need to exchange dollars for euros before I ...   \n",
              "12  The exchange rate between the pound and the eu...   \n",
              "13  As a child, I used to spend my summers at my g...   \n",
              "14  After years of working for a multinational cor...   \n",
              "15  My great-grandfather fought in World War II, a...   \n",
              "16  When I was in college, I spent a semester stud...   \n",
              "17  My best friend and I have been planning a trip...   \n",
              "18  My parents own a small motel in a charming sea...   \n",
              "19  Johnson and I decided to take a road trip acro...   \n",
              "\n",
              "                                               target  \n",
              "0   {'Person': 'John Wick', 'Time': 'several month...  \n",
              "1   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "2   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "3   {'Person': 'null', 'Time': 'years', 'Currency'...  \n",
              "4   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "5   {'Person': 'null', 'Time': 'months', 'Currency...  \n",
              "6   {'Person': 'Mary', 'Time': 'null', 'Currency':...  \n",
              "7   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "8   {'Person': 'null', 'Time': 'semester', 'Curren...  \n",
              "9   {'Person': 'null', 'Time': 'weeks', 'Currency'...  \n",
              "10  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "11  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "12  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "13  {'Person': 'null', 'Time': ['summers', 'those ...  \n",
              "14  {'Person': 'null', 'Time': 'years', 'Currency'...  \n",
              "15  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "16  {'Person': 'null', 'Time': 'semester', 'Curren...  \n",
              "17  {'Person': 'null', 'Time': ['years', 'summer']...  \n",
              "18  {'Person': 'null', 'Time': 'over 20 years', 'C...  \n",
              "19  {'Person': 'Johnson', 'Time': 'summer', 'Curre...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_dict={\"text\":prompt, \"target\":target}\n",
        "df=pd.DataFrame(my_dict)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBe6r_19v9fO"
      },
      "outputs": [],
      "source": [
        "X=df[\"text\"]\n",
        "y=df[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rWBYqiR8CHbc",
        "outputId": "fc259f84-8141-4d76-d7c9-7952e19d4b16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system=\"\"\"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\n",
        "<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time \\\n",
        "like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, \\\n",
        "'Place':<settlement like country, city, district etc.> </labels>\"\"\"\n",
        "system\n",
        "# commonly used delimiters:\n",
        "# triple quotes: \"\"\"\n",
        "# triple backticks: '''\n",
        "# riple dashes: ___\n",
        "# angle brackets : <>\n",
        "# curly brackets: {}\n",
        "# XML tags: <tag> </tag> ---> <text>This is sentence</text>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnuvrc2FCRy3"
      },
      "outputs": [],
      "source": [
        "#system=\"\"\"Extract {labels} from text and return them in dict type.\n",
        "#labels: 'Person (name, surname)', 'Time (this week, last month, summer, next month etc.)', 'Currency (USD, EURO, etc.)', 'Place (country, city, etc.)'.\"\"\" #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw_wCp3irWtz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def convert_df_to_dict(X, y):\n",
        "  \"\"\"Converts X and y to dictionary format.\n",
        "\n",
        "  Args:\n",
        "    X: text\n",
        "    y: label\n",
        "\n",
        "  Returns:\n",
        "    A dataframe(as X and y) in dictionary format.\n",
        "  \"\"\"\n",
        "  #df = pd.read_csv(csv_file)\n",
        "  json_lines = []\n",
        "  for i, j in zip(X, y):\n",
        "    json_lines.append({\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": i\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": str(j) # We convert assistant content in dictionary format to string.\n",
        "            }                     # All content must be strings, otherwise you will get an error in the Format validation section.\n",
        "        ]\n",
        "    })\n",
        "\n",
        "  return json_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCsO_z3qJEqZ"
      },
      "outputs": [],
      "source": [
        "train=convert_df_to_dict(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVwTSGxKP1u3",
        "outputId": "dcf759d8-30b5-4971-b03c-5cd13ea3f6eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': \"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\"},\n",
              "  {'role': 'user',\n",
              "   'content': 'After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"{'Person': 'John Wick', 'Time': 'several months', 'Currency': 'null', 'Place': 'Spain'}\"}]}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZrT07WQymOA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.jsonl\", \"w\") as f:\n",
        "    for item in train:\n",
        "        f.write(json.dumps(item) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACoGWUdfy_oM"
      },
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        "\n",
        "**Data loading**, **Format validation**, **Token Counting Utilities**, **Data Warnings and Token Counts**, ve **Cost Estimation** bölümleri için aşağıdaki kod blokları OpenAI tarafından hazırlanmıştır. Ve ince ayardan önce kullanılması tavsiye edilir.\n",
        "\n",
        "Bu kod blokları, bir chatgpt modeline ince ayar yapmak için kullanılan datayı önceden işlemek ve analiz etmek için bir araç görevi görür. Biçim hatalarını kontrol eder, temel istatistikler sağlar ve ince ayar maliyetini belirlemek için gerekli olan token sayılarını tahmin eder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRbs4Px5zD_O"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTc7l0-8zLwz"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "We first load the chat dataset from an example JSONL file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt3gSCRpzOc3",
        "outputId": "14a3f573-7105-49c6-9b27-d687bf3c3ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 20\n",
            "First example:\n",
            "{'role': 'system', 'content': \"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\"}\n",
            "{'role': 'user', 'content': 'After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.'}\n",
            "{'role': 'assistant', 'content': \"{'Person': 'John Wick', 'Time': 'several months', 'Currency': 'null', 'Place': 'Spain'}\"}\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/train.jsonl\" # data_path variable specifies the path to the jsonl file.\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f: # with open() opens the file and loads each line as a dict object using json.loads().\n",
        "\n",
        "    dataset = [json.loads(line) for line in f] # we assign all dict objects to the dataset list.\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs-LTmYAzbsg"
      },
      "source": [
        "## Format validation\n",
        "\n",
        "We can perform various error checks to verify that each observation in the dataset conforms to the format expected by the fine-tuning API. Errors are categorized according to their nature for easier debugging.\n",
        "\n",
        "1.**Data Type Check: Checks whether each entry in the dataset is a dictionary (dict). Error type: data_type.\n",
        "\n",
        "2.**Presence of Message List: Checks if there is a message list for each entry. Error type: missing_messages_list.\n",
        "\n",
        "3.**Message Keys Check: Checks for the presence of “role” and “content” keys in messages. Error type: message_missing_key.\n",
        "\n",
        "4.**Unrecognized Keys in Messages: Checks if a message has keys other than “role”, “content” and name(system, user, assistant). Error type: message_unrecognized_key.\n",
        "\n",
        "5.**Role Validation: Confirms whether the “roles” are “system”, “user”, or “assistant”. Error type: unrecognized_role.\n",
        "\n",
        "6.**Content Validation (content validation)**: confirms that the content is a string expression. Error type: missing_content.\n",
        "\n",
        "7.**Assistant Message Presence: **: checks if the message contains content belonging to the assistant. Error type: example_missing_assistant_message.\n",
        "\n",
        "The following code performs these checks and prints the number of any errors found. This is useful for debugging and checking if the dataset is ready for the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M3niQ78z_Se",
        "outputId": "ae62fe30-a810-450e-fa9f-82a3f73ce8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# This function checks if the data is ready for fine tuning. It returns an error for missing or invalid data.\n",
        "# returns the message “No error found” if there is no problem with the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2jSHp0y0jBx"
      },
      "source": [
        "## Token Counting Utilities\n",
        "\n",
        "Lets define a few helpful utilities to be used in the rest of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJNuG6gr0l-P"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.05)}, {np.quantile(values, 0.95)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRZOQX8E3mgY"
      },
      "source": [
        "## Data Warnings and Token Counts\n",
        "\n",
        "With the following analyses, we can identify potential problems in the data, missing messages and provide statistical information about message and token counts.\n",
        "\n",
        "1.**Missing System/User Messages**: Counts observations that are missing “system” or “user” messages. These messages are critical for identifying the assistant's behavior and initiating the conversation.\n",
        "\n",
        "2.**Number of Messages Per Example**: Summarizes the distribution of the number of messages (system, user, assistant) in each observation and provides information about the dialog complexity. It checks if each message has 3 separate parts: system, user, assistant. If so, the min, max, mean, median, 5% and 95% of the number of parts in each message will always be 3. Otherwise, these values will be different from 3.\n",
        "\n",
        "3.**Total Tokens Per Example**: Calculates and summarizes the distribution of the total number of tokens in each observation. It is important to understand the fine-tuning costs. This provides information about the total number of tokens and their distribution (mean, median, minimum, maximum, etc.) in each message, including system, user and assistant parts.\n",
        "\n",
        "4.**Tokens in Assistant's Messages**: calculates the number of tokens in assistant's messages in each observation and summarizes this distribution (mean, median, minimum, maximum, etc.). Provides information about the assistant.\n",
        "\n",
        "5.**Token Limit Warnings**:  Checks if any observation exceeds the maximum token limit (4096 tokens), because such observations will be clipped during fine-tuning, which will result in data loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k4FwTMZ0pK2",
        "outputId": "9f6fa34e-89b7-453e-c7c7-c8d331a36b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 142, 159\n",
            "mean / median: 151.25, 151.5\n",
            "p5 / p95: 143.9, 159.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 24, 29\n",
            "mean / median: 25.6, 24.5\n",
            "p5 / p95: 24.0, 29.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbOEAqJK3-fI"
      },
      "source": [
        "## Cost Estimation\n",
        "\n",
        "In this section, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. It is worth noting that as the number of tokens increases, the duration of the fine-tuning process will also increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IdZITlY4Abs",
        "outputId": "d1284555-aadb-4f55-a6ce-1a5000d6fd1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has ~3025 tokens that will be charged for during training\n",
            "By default, you'll train for 5 epochs on this dataset\n",
            "By default, you'll be charged for ~15125 tokens\n",
            "Estimate total costs ~0.121\n"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "current_price=8 # Price per one million tokens, please check the openai webpage for the current price.\n",
        "print(f\"Estimate total costs ~{(n_epochs * n_billing_tokens_in_dataset)/1000000 * current_price}\")\n",
        "\n",
        "# At least 10 observations must be given to the model for fine tuning. Otherwise the model will return an error. However, it is recommended to give the model a minimum of 100 and a maximum of 25000 observations for fine tuning.\n",
        "\n",
        "# GPT 3.5-Turbo model works with 3 epochs by default for fine tuning. However, this script will suggest you how many epochs you should train, from a minimum of 1 to a maximum of 25, based on the number of observations in your data.\n",
        "\n",
        "# Returns the number of tokens to process over the entire training and the cost of fine-tuning based on that number of tokens.\n",
        "\n",
        "# NOTE: This section will only apply to training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqyOWQZQ4H2u",
        "outputId": "58aab98c-ba72-41ef-fd57-ee4810c39c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-QETofvgMzM3vaF3XZ7HywbLP\n"
          ]
        }
      ],
      "source": [
        "training_response = client.files.create(\n",
        "                                        file=open(\"/content/train.jsonl\", \"rb\"),\n",
        "                                        purpose=\"fine-tune\") # We prepare Train data for fine tuning.\n",
        "\n",
        "training_file_id = training_response.id # We pull the ID created for the ready train data.\n",
        "\n",
        "print(\"Training file id:\", training_file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F702yNIP4bVH",
        "outputId": "e5837f73-4a86-4858-8b73-4e542f8bea02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FineTuningJob(id='ftjob-aT6Qa2uYF6puBDD0i21tHPIB', created_at=1713810490, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=2062274915, status='validating_files', trained_tokens=None, training_file='file-QETofvgMzM3vaF3XZ7HywbLP', validation_file=None, integrations=[], user_provided_suffix='NER')\n"
          ]
        }
      ],
      "source": [
        "suffix_name = \"NER\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id, # The ID of the train data is given to the fine-tuning model. The ID of the train data must be provided\n",
        "    model=\"gpt-3.5-turbo\", # For now the only model available is the GPT-3.5-turbo. We expect GPT-4 to be available in the near future.\n",
        "    suffix=suffix_name, # We can add a suffix of our choice to the name of the fine-tuned model, but we cannot specify the exact name of the model.\n",
        "    hyperparameters={\"n_epochs\":5}, # We are only allowed to set the Epoch, batch size parameter. We are not allowed to edit other parameters.\n",
        "                                    # Since the recommended number of epochs is 3, we set epoch to 3.\n",
        ")\n",
        "\n",
        "job_id = response.id # The ID of fine-tune model.\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9ZZte7beSdkh",
        "outputId": "38f31924-5d1a-4baf-912e-15628730d9b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ftjob-aT6Qa2uYF6puBDD0i21tHPIB'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NsEywLJ4ref",
        "outputId": "2d93da32-23e9-4bf0-fa96-e9dba660e800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-aT6Qa2uYF6puBDD0i21tHPIB', created_at=1713810490, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:ner:9GsmiFLb', finished_at=1713810866, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=['file-fTM0sgqWT3VOWfnworyX3dTm'], seed=2062274915, status='succeeded', trained_tokens=14925, training_file='file-QETofvgMzM3vaF3XZ7HywbLP', validation_file=None, integrations=[], user_provided_suffix='NER')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # We get general information about fine tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSL-R7PZ4u39",
        "outputId": "06e02dee-8d0d-46e5-cabf-65b76a45e35f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-H6XABXfSnbzVMSy6fnmlyJu6', created_at=1713810871, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-6yc2zMygNvLLiijQd3PkeOcc', created_at=1713810868, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:ner:9GsmiFLb', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-mDGIe4Bctt7j5CXKBS9YqgqI', created_at=1713810868, level='info', message='Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner:9GsmhsGl:ckpt-step-80', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-BRFRAp0sI7SU1Na8cmavpdfQ', created_at=1713810868, level='info', message='Checkpoint created at step 60 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner:9GsmhhNB:ckpt-step-60', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-S5iPTmrmFr1eUNVqvsnFzh32', created_at=1713810863, level='info', message='Step 100/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 100, 'train_loss': 4.238552548940788e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-9K1wzoqUvxEF9khE3JE3saOb', created_at=1713810860, level='info', message='Step 99/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 99, 'train_loss': 4.4015737898916996e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-MBDdpVmCP2XmNUDrx9gtbXx4', created_at=1713810858, level='info', message='Step 98/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 98, 'train_loss': 4.4015737898916996e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-UkH6HoymRAkzf0shacPBlXro', created_at=1713810855, level='info', message='Step 97/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 97, 'train_loss': 4.4015737898916996e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-IK6wSTtdxoHLEAvkrpBzVyrh', created_at=1713810855, level='info', message='Step 96/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 96, 'train_loss': 4.4015737898916996e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-7Vu2h2xcyA9qxYFa2ZgRNncq', created_at=1713810853, level='info', message='Step 95/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 95, 'train_loss': 5.868765242666996e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')], object='list', has_more=True)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10) # Displays the events of the fine-tuning process in the last 10 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrHbhby25Rve",
        "outputId": "539f2b91-d766-4e1d-cf06-8fd443f37933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 75/100: training loss=0.00\n",
            "Step 76/100: training loss=0.00\n",
            "Step 77/100: training loss=0.00\n",
            "Step 78/100: training loss=0.00\n",
            "Step 79/100: training loss=0.00\n",
            "Step 80/100: training loss=0.48\n",
            "Step 81/100: training loss=0.00\n",
            "Step 82/100: training loss=0.00\n",
            "Step 83/100: training loss=0.46\n",
            "Step 84/100: training loss=0.00\n",
            "Step 85/100: training loss=0.00\n",
            "Step 86/100: training loss=0.00\n",
            "Step 87/100: training loss=0.00\n",
            "Step 88/100: training loss=0.00\n",
            "Step 89/100: training loss=0.00\n",
            "Step 90/100: training loss=0.00\n",
            "Step 91/100: training loss=0.00\n",
            "Step 92/100: training loss=0.00\n",
            "Step 93/100: training loss=0.38\n",
            "Step 94/100: training loss=0.00\n",
            "Step 95/100: training loss=0.00\n",
            "Step 96/100: training loss=0.00\n",
            "Step 97/100: training loss=0.00\n",
            "Step 98/100: training loss=0.00\n",
            "Step 99/100: training loss=0.00\n",
            "Step 100/100: training loss=0.00\n",
            "Checkpoint created at step 60 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner:9GsmhhNB:ckpt-step-60\n",
            "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner:9GsmhsGl:ckpt-step-80\n",
            "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:ner:9GsmiFLb\n",
            "The job has successfully completed\n"
          ]
        }
      ],
      "source": [
        "response= client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=30)\n",
        "\n",
        "events=response.data\n",
        "\n",
        "events.reverse() # We reverse the order of the fine-tuning steps using the reverse() function, with the first steps of the fine-tuning process at the beginning.\n",
        "\n",
        "for event in events:\n",
        "  print(event.message)\n",
        "\n",
        "# We get the training loss scores for each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAfZutEWVkwH",
        "outputId": "f8f238c8-1f1a-4f7f-83bb-c7e3fe2c6e49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-nKraJjw1ggsXvBT8TNkrSoZw', created_at=1713810376, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=483893693, status='cancelled', trained_tokens=None, training_file='file-QETofvgMzM3vaF3XZ7HywbLP', validation_file=None, integrations=[], user_provided_suffix='NER')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#client.fine_tuning.jobs.cancel(job_id)\n",
        "\n",
        "# You can cancel the fine-tuning process you have started with this code. However, the fine-tuning process will start in 5-10 minutes,\n",
        "# so you need to cancel it before that. If you don't, you won't be able to cancel it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jgiLQPuV1JC"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq8jJwcKV6qd",
        "outputId": "de4f1526-bfcf-47fa-c29d-4ecb01d04a9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-aT6Qa2uYF6puBDD0i21tHPIB', created_at=1713810490, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:ner:9GsmiFLb', finished_at=1713810866, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=['file-fTM0sgqWT3VOWfnworyX3dTm'], seed=2062274915, status='succeeded', trained_tokens=14925, training_file='file-QETofvgMzM3vaF3XZ7HywbLP', validation_file=None, integrations=[], user_provided_suffix='NER')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # First we get general information about fine-tuning. from here we will draw the fine-tune model name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KuSeT27fp6fu",
        "outputId": "afd63d2c-b669-4ca4-9962-6758bb2beb66"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ft:gpt-3.5-turbo-0125:personal:ner:9GsmiFLb'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name= client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model # we pull the model name.\n",
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4VHMw78kN1",
        "outputId": "a929b8fa-6fa2-491a-d8c1-ef5fdd112b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Person': 'null', 'Time': 'null', 'Currency': 'null', 'Place': 'null'}\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"My grandmother was a talented seamstress, and she taught me how to sew when I was young, which sparked a lifelong passion for fashion and design.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEH9Asxy-BW3",
        "outputId": "171688a7-6477-45dd-92bc-19290ca1413f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Person': 'Joseph', 'Time': 'summer', 'Currency': ['dollars', 'euros'], 'Place': 'Turkey'}\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"While I was on summer vacation, Joseph earned 100 dollars and 100 euros in Turkey and returned to America.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXCUPZMk-Wo9",
        "outputId": "ca063cb0-1f19-4b23-f9c2-c6f015c6ebee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Person': 'Johnson Walker and Maria', 'Time': 'last month', 'Currency': 'sterling pounds', 'Place': 'London'}\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"Johnson Walker and Maria got married last month. They bought a house in London for 100,000 sterling pounds.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "END OF THE PROJECT"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
