{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT API Fine Tuning for Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBRzu-Yk4Btb"
      },
      "source": [
        "Try gpt for your task before fine-tuning. If chatgpt is not enough, then fine-tune it. Do not forget that chat-gpt may be sufficient for most simple tasks.\n",
        "\n",
        "To fine-tune the GPT-3.5 model, you need to convert each observation in your data to the following message template (Jsonline Format):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_X9Ptrr5HoJ"
      },
      "outputs": [],
      "source": [
        "# \"{'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
        "#                {'role': 'user', 'content': 'It is a very nice pair of pants. I recommend it to everyone.'},\n",
        "#                {'role': 'assistant', 'content': 'possitive'}]}\"\n",
        "\n",
        "# system: the instructions you give to the model.\n",
        "# user: the feature/independent variable/text of each observation in your data (X)\n",
        "# assistant: the dependent variable/target/label of each observation in your data (y)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b7oLIrkJnHm",
        "outputId": "030ac868-b5ef-4c7d-bc9a-461d26142d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5ZLFxvoohMT",
        "outputId": "1dc0e3bd-2908-4dfe-e94c-5da56d4f7798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOqXTmLNk47Q",
        "outputId": "e6902813-a099-47c7-e20f-82f5d8d0448a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yR7fCAUpkrJY"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0D2xCVuUk2Ax",
        "outputId": "7833d039-c7ed-41b0-e3f0-cbc4547900c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"# We will fine-tune a data set with 1059 observations\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When i read all these positive reviews i did not hesitated, as i wanted good basics which will be good investment in me as looking good is always investment. well, i love blue color as i am blonde wih blue eyes and this color makes my eyes brighter and matches almost everything but..the design of the shirt is made oversize fit basically the shirt should not be dressed as fitted it's more relaxed fit so if you wear medium go head and order medium even if the small fits unless you want to look lik\",\n          \"Such a festive sweater and i've received many compliments anytime i wear it. unique and fun to wear!\",\n          \"The colors in this cardigan are not what they look like on line. the top is navy and the lower arms are grey. the sweater overall has more punch than pictured. this is a cotton sweater and a great fall layering piece. it will look great with a tee shirt and jeans. it is a long sweater, but not too long as to swallow a smaller person up. i also really like that the front is not too flowy. i am looking forward to wearing this all fall.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f5a3672b-f1d5-44d3-adc4-45fec8ad18ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This sweater is heavier and has more of a swin...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When i read all these positive reviews i did n...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The colors in this cardigan are not what they ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Perfect! very pretty and flattering without be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Such a festive sweater and i've received many ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5a3672b-f1d5-44d3-adc4-45fec8ad18ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5a3672b-f1d5-44d3-adc4-45fec8ad18ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5a3672b-f1d5-44d3-adc4-45fec8ad18ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb9f3b14-2fde-4522-be60-e1fe58a2d80b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb9f3b14-2fde-4522-be60-e1fe58a2d80b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb9f3b14-2fde-4522-be60-e1fe58a2d80b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text     label\n",
              "0  This sweater is heavier and has more of a swin...  positive\n",
              "1  When i read all these positive reviews i did n...  negative\n",
              "2  The colors in this cardigan are not what they ...  positive\n",
              "3  Perfect! very pretty and flattering without be...  positive\n",
              "4  Such a festive sweater and i've received many ...  positive"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/clothing_reviews.csv\")\n",
        "df.head()\n",
        "\n",
        "# We will fine-tune a data set with 1059 observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffdfINE6EcHV",
        "outputId": "dfb51014-488e-4677-b40d-7ef9f2db1661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1059"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "KxG1fd_UlXE3",
        "outputId": "e8b8252b-6bd4-408d-cefa-8bdadc455c5d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.fig = plt.figure(figsize = (7,5))\n",
        "ax = sns.countplot(x=\"label\",\n",
        "                   data=df)\n",
        "ax.bar_label(ax.containers[0]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVUoaIGhlkGY",
        "outputId": "8901e5a5-986e-425f-e055-85dd906da3fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_6dYx0KAu5Z4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spR4NNO81iWr",
        "outputId": "dafdf8d8-5fc3-4337-cd4a-efc1582e9ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "953\n",
            "106\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiJz3_qFoXLt",
        "outputId": "fd933174-56cd-4291-c3c8-f9dc7a8a8c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "814    I don't usually wear this much color, but i'm ...\n",
              "599    I have been wanting this sweater and decided t...\n",
              "462    I love the color and cut of the pants. they ar...\n",
              "466    Runs almost two sizes small. i plan to wear as...\n",
              "620    I noticed this outfit earlier this year and re...\n",
              "                             ...                        \n",
              "297    These jeans are very comfortable. the distress...\n",
              "963    Wow, i got this top in blue and i'm in love. l...\n",
              "74     Tts and comfortable. this t shirt brings flair...\n",
              "313    This dress is amazing! it's perfect for a casu...\n",
              "728    I have been wanting this coat ever since i tri...\n",
              "Name: text, Length: 953, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY6NHIN0lzEf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def convert_df_to_dict(X, y):\n",
        "  \"\"\"Converts X and y to dictionary format.\n",
        "\n",
        "  Args:\n",
        "    X: text\n",
        "    y: label\n",
        "\n",
        "  Returns:\n",
        "    A dataframe(as X and y) in dictionary format.\n",
        "  \"\"\"\n",
        "\n",
        "  dictionary = []\n",
        "  for i, j in zip(X, y):\n",
        "    dictionary.append({\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Detect sentiment in the text.\" # system content will be the same for all observations.\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": i\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": j\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "  return dictionary\n",
        "\n",
        "# To convert observations to JSONLine format, we first need to convert them to dictionary format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3kUGrxlraUQ"
      },
      "outputs": [],
      "source": [
        "train = convert_df_to_dict(X_train, y_train)\n",
        "test = convert_df_to_dict(X_test, y_test)\n",
        "\n",
        "# We convert train and test data into dictionary format separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6TOTzsA9rM",
        "outputId": "5db78e81-ce9f-47a1-e7c3-b4533d14e9e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
              "   {'role': 'user',\n",
              "    'content': \"I don't usually wear this much color, but i'm so glad i purchased this top. it is really cute on and professional enough for work, but with a tank underneath and the buttons undone, its casual too. i have received several compliments both times i have worn the shirt. sleeves are a bit long.\"},\n",
              "   {'role': 'assistant', 'content': 'positive'}]},\n",
              " {'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'I have been wanting this sweater and decided to order. when i received it, there was no tag on the product. it was not in a typical clear bag from retailer and it wasn\\'t packaged nicely. it came from reno, nv. most products i order do not get shipped from there. it is short, and i\\'m 5\\'1\". most clothes that are short fit me with no problem. this sweater might hit me at the waist, or maybe shorter. i think the color is nice and the sweater is soft but not what i wanted. i am going to return it'},\n",
              "   {'role': 'assistant', 'content': 'negative'}]}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEHj56gOTTE",
        "outputId": "568d7ed8-8079-412e-e562-70c78c8a17ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train[0]) # the type of observations is dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7M9n1ozKjDN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.jsonl\", \"w\") as f:\n",
        "    for item in train:\n",
        "        f.write(json.dumps(item) + \"\\n\") # Python uses the json.dumps() function to convert a dictionary to JSON format.\n",
        "                                         # This function converts the dictionary into a JSON string.\n",
        "\n",
        "# The train and test data that we will feed to the model for fine tuning should be in JSON line format. For this, all observations in dictionary format\n",
        "# We convert to JSON line format.\n",
        "\n",
        "# JSON format is the conversion of dictionary format to string.\n",
        "\n",
        "# dict format: {'name': 'johnson', 'age':44}\n",
        "# json format: “{‘name’: ‘johnson’, ‘age’:‘44’}”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NRNwOh9KvhR"
      },
      "outputs": [],
      "source": [
        "with open(\"test.jsonl\", \"w\") as f:\n",
        "    for item in test:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "# We apply the same JSON line transformation to the test data as we did to the train data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCL6YmEcR2Bi",
        "outputId": "cd92439a-7be3-46d6-d666-e5a563fb5523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"Detect sentiment in the text.\"}, {\"role\": \"user\", \"content\": \"I don't usually wear this much color, but i'm so glad i purchased this top. it is really cute on and professional enough for work, but with a tank underneath and the buttons undone, its casual too. i have received several compliments both times i have worn the shirt. sleeves are a bit long.\"}, {\"role\": \"assistant\", \"content\": \"positive\"}]}\n",
            "\n",
            "<class 'str'>\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"Detect sentiment in the text.\"}, {\"role\": \"user\", \"content\": \"I have been wanting this sweater and decided to order. when i received it, there was no tag on the product. it was not in a typical clear bag from retailer and it wasn't packaged nicely. it came from reno, nv. most products i order do not get shipped from there. it is short, and i'm 5'1\\\". most clothes that are short fit me with no problem. this sweater might hit me at the waist, or maybe shorter. i think the color is nice and the sweater is soft but not what i wanted. i am going to return it\"}, {\"role\": \"assistant\", \"content\": \"negative\"}]}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import codecs\n",
        "\n",
        "with codecs.open('train.jsonl', 'r', encoding='utf-8') as f:\n",
        "  a = 0\n",
        "  for line in f:\n",
        "    print(type(line))\n",
        "    print(line)\n",
        "    a+=1\n",
        "\n",
        "    if a==2:\n",
        "      break\n",
        "\n",
        "# We can see that all observations converted to JSON line format are in string type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3I4tzySovp"
      },
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        "\n",
        "\n",
        "**Data loading**, **Format validation**, **Token Counting Utilities**, **Data Warnings and Token Counts**, ve **Cost Estimation** bölümleri için aşağıdaki kod blokları OpenAI tarafından hazırlanmıştır. Ve ince ayardan önce kullanılması tavsiye edilir.\n",
        "\n",
        "Bu kod blokları, bir chatgpt modeline ince ayar yapmak için kullanılan datayı önceden işlemek ve analiz etmek için bir araç görevi görür. Biçim hatalarını kontrol eder, temel istatistikler sağlar ve ince ayar maliyetini belirlemek için gerekli olan token sayılarını tahmin eder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UAjU36rTJpL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ws8lfn7TPzF"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "We first load the chat dataset from an example JSONL file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DA0XyMBTLe5",
        "outputId": "fc502bd1-4830-4803-fd54-e669d12b8020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 953\n",
            "First example:\n",
            "<class 'dict'>\n",
            "{'role': 'system', 'content': 'Detect sentiment in the text.'}\n",
            "<class 'dict'>\n",
            "{'role': 'user', 'content': \"I don't usually wear this much color, but i'm so glad i purchased this top. it is really cute on and professional enough for work, but with a tank underneath and the buttons undone, its casual too. i have received several compliments both times i have worn the shirt. sleeves are a bit long.\"}\n",
            "<class 'dict'>\n",
            "{'role': 'assistant', 'content': 'positive'}\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/train.jsonl\" # data_path değişkeni jsonl dosyasının yolunu belirtir.\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f: # with open() dosyayı açar ve json.loads() işlevini\n",
        "                                                  # kullanarak her satırı bir dict nesnesi olarak yükler.\n",
        "\n",
        "    dataset = [json.loads(line) for line in f] # tüm dict nesnelerini dataset listesine atıyoruz.\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(type(message))\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qfu9GeYTjxZ"
      },
      "source": [
        "## Format validation\n",
        "\n",
        "We can perform various error checks to verify that each observation in the dataset conforms to the format expected by the fine-tuning API. Errors are categorized according to their nature for easier debugging.\n",
        "\n",
        "1.**Data Type Check: Checks whether each entry in the dataset is a dictionary (dict). Error type: data_type.\n",
        "\n",
        "2.**Presence of Message List: Checks if there is a message list for each entry. Error type: missing_messages_list.\n",
        "\n",
        "3.**Message Keys Check: Checks for the presence of “role” and “content” keys in messages. Error type: message_missing_key.\n",
        "\n",
        "4.**Unrecognized Keys in Messages: Checks if a message has keys other than “role”, “content” and name(system, user, assistant). Error type: message_unrecognized_key.\n",
        "\n",
        "5.**Role Validation: Confirms whether the “roles” are “system”, “user”, or “assistant”. Error type: unrecognized_role.\n",
        "\n",
        "6.**Content Validation (content validation)**: confirms that the content is a string expression. Error type: missing_content.\n",
        "\n",
        "7.**Assistant Message Presence: **: checks if the message contains content belonging to the assistant. Error type: example_missing_assistant_message.\n",
        "\n",
        "The following code performs these checks and prints the number of any errors found. This is useful for debugging and checking if the dataset is ready for the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaCwPIfrTLmR",
        "outputId": "ccba9e94-e236-420a-83cd-d61970a1c2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# This function checks if the data is ready for fine tuning. It returns an error for missing or invalid data.\n",
        "# returns the message “No error found” if there is no problem with the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esD69V_LTrwJ"
      },
      "source": [
        "## Token Counting Utilities\n",
        "\n",
        "Lets define a few helpful utilities to be used in the rest of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wxxwwAgTLtI"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.05)}, {np.quantile(values, 0.95)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTgrQJlcT6CP"
      },
      "source": [
        "## Data Warnings and Token Counts\n",
        "\n",
        "With the following analyses, we can identify potential problems in the data, missing messages and provide statistical information about message and token counts.\n",
        "\n",
        "1.**Missing System/User Messages**: Counts observations that are missing “system” or “user” messages. These messages are critical for identifying the assistant's behavior and initiating the conversation.\n",
        "\n",
        "2.**Number of Messages Per Example**: Summarizes the distribution of the number of messages (system, user, assistant) in each observation and provides information about the dialog complexity. It checks if each message has 3 separate parts: system, user, assistant. If so, the min, max, mean, median, 5% and 95% of the number of parts in each message will always be 3. Otherwise, these values will be different from 3.\n",
        "\n",
        "3.**Total Tokens Per Example**: Calculates and summarizes the distribution of the total number of tokens in each observation. It is important to understand the fine-tuning costs. This provides information about the total number of tokens and their distribution (mean, median, minimum, maximum, etc.) in each message, including system, user and assistant parts.\n",
        "\n",
        "4.**Tokens in Assistant's Messages**: calculates the number of tokens in assistant's messages in each observation and summarizes this distribution (mean, median, minimum, maximum, etc.). Provides information about the assistant.\n",
        "\n",
        "5.**Token Limit Warnings**:  Checks if any observation exceeds the maximum token limit (4096 tokens), because such observations will be clipped during fine-tuning, which will result in data loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmwM6puTLzu",
        "outputId": "68f3e685-3a01-4c92-f2dd-49142e30659e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 29, 166\n",
            "mean / median: 94.63588667366211, 93.0\n",
            "p5 / p95: 43.0, 145.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 1, 1\n",
            "mean / median: 1.0, 1.0\n",
            "p5 / p95: 1.0, 1.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv-y846P_hZy"
      },
      "source": [
        "NOTE: For test data, the Data loading, Format validation, Token Counting Utilities, Data Alerts and Token Counts sections also need to be done. We have done this only for training data to keep the notebook short.\n",
        "But the cost estimation section is only done for training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrNGRzLzUMuu"
      },
      "source": [
        "## Cost Estimation\n",
        "\n",
        "##### In this section, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. <br> It is worth noting that as the number of tokens increases, the duration of the fine-tuning process will also increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm2stEhQ-4_X",
        "outputId": "f70126b2-17a8-49f3-8fc3-5eb817f78c66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "100//30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6iFu2fCUQLB",
        "outputId": "62629451-69ea-4494-dee1-3617bb258e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has ~90188 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~270564 tokens\n",
            "Estimate total costs ~2.164512\n"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:  # if the product of the number of observations in the train data and TARGET_EPOCHS(3) is less than MIN_TARGET_EXAMPLES(100),\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples) # the smaller of MAX_DEFAULT_EPOCHS(25) or 100//(number of observations in train data) as epoch\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES: # if the number of observations in the train data times TARGET_EPOCHS(3) is greater than MAX_TARGET_EXAMPLES(2500),\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples) # epoch as MIN_DEFAULT_EPOCHS(1) or MIN_TARGET_EXAMPLES(25000)//(number of observations in train data) whichever is greater\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens) # total number of tokens for all comments, with a maximum number of tokens per comment not exceeding 4096\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\") # total number of tokens trained\n",
        "\n",
        "current_price=8 # Price per one million tokens, please check the openai webpage for the current price.\n",
        "print(f\"Estimate total costs ~{(n_epochs * n_billing_tokens_in_dataset)/1000000 * current_price}\")\n",
        "\n",
        "# At least 10 observations must be given to the model for fine tuning. Otherwise the model will return an error. \n",
        "# However, for fine tuning, the model should be given a minimum of 100 and a maximum of 25000 observation is recommended.\n",
        "\n",
        "# GPT 3.5-Turbo model works with 3 epochs by default for fine tuning. However, this code can be adjusted from a minimum of 1 to a maximum of 25, depending on the number of observations in your data.\n",
        "# Suggests how many epochs of training you need to do.\n",
        "\n",
        "# Returns the number of tokens to process over the entire training and the cost of fine-tuning based on this number of tokens.\n",
        "\n",
        "# NOTE: This section will only apply to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Mo4ro3p83PC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yS3Hvp_gJw8O"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qby3xDv2JYC8",
        "outputId": "9a786313-1ead-40af-f6f2-b5acd8a20261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-sXjDiGxp7D7XreO01jg4nXqr\n",
            "Validation file id: file-E2ZWEdC8g2iX1pAOIAIS7SSh\n"
          ]
        }
      ],
      "source": [
        "training_response = client.files.create(file=open(\"/content/train.jsonl\", \"rb\"),\n",
        "                                        purpose=\"fine-tune\") # We prepare Train data for fine tuning.\n",
        "\n",
        "training_file_id = training_response.id # We pull the ID created for the ready train data.\n",
        "\n",
        "validation_response = client.files.create(file=open(\"/content/test.jsonl\", \"rb\"),\n",
        "                                          purpose=\"fine-tune\") # We prepare the test data for fine tuning.\n",
        "\n",
        "validation_file_id = validation_response.id # We retrieve the ID created for the ready test data.\n",
        "\n",
        "print(\"Training file id:\", training_file_id)\n",
        "print(\"Validation file id:\", validation_file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgw1dpVcVgPZ",
        "outputId": "7e18668f-ff75-4ad3-aa98-68e95abc9e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FineTuningJob(id='ftjob-wHqUPL5DJQ1zQmfoWz2VgRkM', created_at=1713607674, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=1700530180, status='validating_files', trained_tokens=None, training_file='file-sXjDiGxp7D7XreO01jg4nXqr', validation_file='file-E2ZWEdC8g2iX1pAOIAIS7SSh', integrations=[], user_provided_suffix='sentiment analys 3')\n"
          ]
        }
      ],
      "source": [
        "suffix_name = \"sentiment analys 3\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id, # The ID of the train data is given to the fine-tuning model. The ID of the train data must be provided\n",
        "    validation_file=validation_file_id, #The ID of the validation dats is given to the fine-tuning model. Providing this ID is optional\n",
        "    model=\"gpt-3.5-turbo\", # For now the only model available is the GPT-3.5-turbo. We expect GPT-4 to be available in the near future.\n",
        "    suffix=suffix_name, # We can add a suffix of our choice to the name of the fine-tuned model, but we cannot specify the exact name of the model.\n",
        "    hyperparameters={\"n_epochs\":3}, # We are only allowed to set Epoch, batchsize and learning_rate_multiplier.\n",
        "                                    # Since the recommended number of epochs is 3, we set the epoch to 3.\n",
        ")\n",
        "\n",
        "job_id = response.id # The ID of fine-tune model.\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TjcV7BzfomDU",
        "outputId": "0710e02b-5608-44ee-f21e-e342d6a3a521"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ftjob-wHqUPL5DJQ1zQmfoWz2VgRkM'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0gyFbraEiB",
        "outputId": "02b33703-9a0f-4deb-8390-e00fb855e1d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-wHqUPL5DJQ1zQmfoWz2VgRkM', created_at=1713607674, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=1700530180, status='running', trained_tokens=None, training_file='file-sXjDiGxp7D7XreO01jg4nXqr', validation_file='file-E2ZWEdC8g2iX1pAOIAIS7SSh', integrations=[], user_provided_suffix='sentiment analys 3')"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#client.fine_tuning.jobs.retrieve(job_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvYDKRtKFQGj",
        "outputId": "7e16d63a-23c7-43fa-9173-2067dc2ba6a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-wHqUPL5DJQ1zQmfoWz2VgRkM', created_at=1713607674, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq', finished_at=1713612238, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=['file-QdFR8GQ5baDhHlBzO237GqEG'], seed=1700530180, status='succeeded', trained_tokens=264846, training_file='file-sXjDiGxp7D7XreO01jg4nXqr', validation_file='file-E2ZWEdC8g2iX1pAOIAIS7SSh', integrations=[], user_provided_suffix='sentiment analys 3')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # We get general information about fine tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BprXKrBDIvMb",
        "outputId": "dd142e8c-b209-48e7-a700-35cf36f222ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-14LsUN2gSoopBDBXAfIDFVYU', created_at=1713612243, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-n18svbZw0LE4rRFWYocfM5Pl', created_at=1713612240, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-2Tg8aV3RCYI0xs4GbvAnfaHU', created_at=1713612240, level='info', message='Checkpoint created at step 1906 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371HcG:ckpt-step-1906', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-qbXPcJ2RWVm7Fx3a56KAObKl', created_at=1713612240, level='info', message='Checkpoint created at step 953 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371Reu:ckpt-step-953', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-FXfwheS4DV8XLmBoNTSjXgNV', created_at=1713612236, level='info', message='Step 2859/2859: training loss=1.04, full validation loss=0.14', object='fine_tuning.job.event', data={'step': 2859, 'train_loss': 1.039751410484314, 'total_steps': 2859, 'full_valid_loss': 0.138851690592256, 'train_mean_token_accuracy': 0.6666666865348816, 'full_valid_mean_token_accuracy': 0.9874213836477987}, type='metrics'), FineTuningJobEvent(id='ftevent-hU7hNcUHpV7GNXs1luu70WAn', created_at=1713612234, level='info', message='Step 2858/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2858, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-ZhaTgj825icNIREDH29ScxOn', created_at=1713612228, level='info', message='Step 2857/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2857, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-lvuMNRV1khU7lPOWIf0pETEl', created_at=1713612226, level='info', message='Step 2856/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2856, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-bwaxOi4fGryTLO4Jihfwvj7x', created_at=1713612226, level='info', message='Step 2855/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2855, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-aOA03gMtUepSEy0cbEhVRYYo', created_at=1713612224, level='info', message='Step 2854/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2854, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-0g2eC0N3ersaBInwL94EYUt5', created_at=1713612222, level='info', message='Step 2853/2859: training loss=6.13', object='fine_tuning.job.event', data={'step': 2853, 'train_loss': 6.130556106567383, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-Qu7Ke1ZFAbeHjJmHfaVI6Or4', created_at=1713612220, level='info', message='Step 2852/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2852, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-RZWTA86ToIym3ucGrsU0bq9U', created_at=1713612220, level='info', message='Step 2851/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2851, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-qHqrGocmD2OcKjWEMrfCPMhu', created_at=1713612218, level='info', message='Step 2850/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2850, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-9TNnLfNDMNmHBfpyruslJWqq', created_at=1713612216, level='info', message='Step 2849/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2849, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-WBZF0XB0AiQQa3vhxgc4qojG', created_at=1713612214, level='info', message='Step 2848/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2848, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-4FmJXfhfszZlvU1LCNSiiWnv', created_at=1713612214, level='info', message='Step 2847/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2847, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-X5Sta6TkzGmqv4wGv5nxjTo8', created_at=1713612212, level='info', message='Step 2846/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2846, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-el77WxvHyXTcKkpZxkTsMqba', created_at=1713612209, level='info', message='Step 2845/2859: training loss=6.56', object='fine_tuning.job.event', data={'step': 2845, 'train_loss': 6.5570292472839355, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-QXZSQdida6anB9wmGeajpM3W', created_at=1713612207, level='info', message='Step 2844/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2844, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-RvLHdQFS1WIvnBIdond6lapD', created_at=1713612207, level='info', message='Step 2843/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2843, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-dZal5xrKkKKihtORuqKxFvsM', created_at=1713612205, level='info', message='Step 2842/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2842, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-cYai7ueZFRbVpsRPIV5lBxvo', created_at=1713612203, level='info', message='Step 2841/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2841, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-ySi0ccUDCxDltPA2zCVtukrv', created_at=1713612201, level='info', message='Step 2840/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2840, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-yzh1fhlzbaCD7NjCweGcIbNc', created_at=1713612201, level='info', message='Step 2839/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2839, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-8IOAkkjuWIWhB2C3NrtT68M6', created_at=1713612199, level='info', message='Step 2838/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2838, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-i7ao0wjEQhoR4un8A5qsxjYM', created_at=1713612197, level='info', message='Step 2837/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2837, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-fisnRy7eyA47qsziCk4vgLXg', created_at=1713612195, level='info', message='Step 2836/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2836, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-5f3aV5PWZ3ej3v1DdkPS6A4D', created_at=1713612195, level='info', message='Step 2835/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2835, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-J2jPr90ZY3T9QAXesGiSgH8f', created_at=1713612193, level='info', message='Step 2834/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2834, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics')], object='list', has_more=True)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=30) # Displays the events of the fine-tuning process in the last 30 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rynQ-cT5EOi"
      },
      "outputs": [],
      "source": [
        "response= client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
        "\n",
        "events=response.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Voa550aLVpxK"
      },
      "outputs": [],
      "source": [
        "events.reverse()# The first steps of the fine-tuning process will be at the beginning, using the reverse() function\n",
        "                # We reverse the order of the fine-tuning steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGxkxCmsNVz-",
        "outputId": "8a17a18d-1754-43d1-c141-7729b3fd393b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[FineTuningJobEvent(id='ftevent-QXZSQdida6anB9wmGeajpM3W', created_at=1713612207, level='info', message='Step 2844/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2844, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-el77WxvHyXTcKkpZxkTsMqba', created_at=1713612209, level='info', message='Step 2845/2859: training loss=6.56', object='fine_tuning.job.event', data={'step': 2845, 'train_loss': 6.5570292472839355, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-X5Sta6TkzGmqv4wGv5nxjTo8', created_at=1713612212, level='info', message='Step 2846/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2846, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-4FmJXfhfszZlvU1LCNSiiWnv', created_at=1713612214, level='info', message='Step 2847/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2847, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-WBZF0XB0AiQQa3vhxgc4qojG', created_at=1713612214, level='info', message='Step 2848/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2848, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-9TNnLfNDMNmHBfpyruslJWqq', created_at=1713612216, level='info', message='Step 2849/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2849, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-qHqrGocmD2OcKjWEMrfCPMhu', created_at=1713612218, level='info', message='Step 2850/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2850, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-RZWTA86ToIym3ucGrsU0bq9U', created_at=1713612220, level='info', message='Step 2851/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2851, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-Qu7Ke1ZFAbeHjJmHfaVI6Or4', created_at=1713612220, level='info', message='Step 2852/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2852, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-0g2eC0N3ersaBInwL94EYUt5', created_at=1713612222, level='info', message='Step 2853/2859: training loss=6.13', object='fine_tuning.job.event', data={'step': 2853, 'train_loss': 6.130556106567383, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-aOA03gMtUepSEy0cbEhVRYYo', created_at=1713612224, level='info', message='Step 2854/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2854, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-bwaxOi4fGryTLO4Jihfwvj7x', created_at=1713612226, level='info', message='Step 2855/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2855, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-lvuMNRV1khU7lPOWIf0pETEl', created_at=1713612226, level='info', message='Step 2856/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2856, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-ZhaTgj825icNIREDH29ScxOn', created_at=1713612228, level='info', message='Step 2857/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2857, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 1.0}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-hU7hNcUHpV7GNXs1luu70WAn', created_at=1713612234, level='info', message='Step 2858/2859: training loss=0.00', object='fine_tuning.job.event', data={'step': 2858, 'train_loss': 6.35782896551973e-07, 'total_steps': 2859, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-FXfwheS4DV8XLmBoNTSjXgNV', created_at=1713612236, level='info', message='Step 2859/2859: training loss=1.04, full validation loss=0.14', object='fine_tuning.job.event', data={'step': 2859, 'train_loss': 1.039751410484314, 'total_steps': 2859, 'full_valid_loss': 0.138851690592256, 'train_mean_token_accuracy': 0.6666666865348816, 'full_valid_mean_token_accuracy': 0.9874213836477987}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-qbXPcJ2RWVm7Fx3a56KAObKl', created_at=1713612240, level='info', message='Checkpoint created at step 953 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371Reu:ckpt-step-953', object='fine_tuning.job.event', data={}, type='message'),\n",
              " FineTuningJobEvent(id='ftevent-2Tg8aV3RCYI0xs4GbvAnfaHU', created_at=1713612240, level='info', message='Checkpoint created at step 1906 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371HcG:ckpt-step-1906', object='fine_tuning.job.event', data={}, type='message'),\n",
              " FineTuningJobEvent(id='ftevent-n18svbZw0LE4rRFWYocfM5Pl', created_at=1713612240, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq', object='fine_tuning.job.event', data={}, type='message'),\n",
              " FineTuningJobEvent(id='ftevent-14LsUN2gSoopBDBXAfIDFVYU', created_at=1713612243, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qau4-ZN6Dw-2",
        "outputId": "6656cc84-9e70-4afd-c239-c46c53e85976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2844/2859: training loss=0.00\n",
            "Step 2845/2859: training loss=6.56\n",
            "Step 2846/2859: training loss=0.00\n",
            "Step 2847/2859: training loss=0.00\n",
            "Step 2848/2859: training loss=0.00\n",
            "Step 2849/2859: training loss=0.00\n",
            "Step 2850/2859: training loss=0.00\n",
            "Step 2851/2859: training loss=0.00\n",
            "Step 2852/2859: training loss=0.00\n",
            "Step 2853/2859: training loss=6.13\n",
            "Step 2854/2859: training loss=0.00\n",
            "Step 2855/2859: training loss=0.00\n",
            "Step 2856/2859: training loss=0.00\n",
            "Step 2857/2859: training loss=0.00\n",
            "Step 2858/2859: training loss=0.00\n",
            "Step 2859/2859: training loss=1.04, full validation loss=0.14\n",
            "Checkpoint created at step 953 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371Reu:ckpt-step-953\n",
            "Checkpoint created at step 1906 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371HcG:ckpt-step-1906\n",
            "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq\n",
            "The job has successfully completed\n"
          ]
        }
      ],
      "source": [
        "for event in events:\n",
        "    print(event.message) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zq0KkGlafoK"
      },
      "outputs": [],
      "source": [
        "#client.fine_tuning.jobs.cancel(job_id)\n",
        "\n",
        "# You can cancel the fine-tuning process you have started with this code. However, the fine-tuning process will start in 1-2 minutes,\n",
        "# so you need to cancel it before that. If you don't, you won't be able to cancel it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1r1xR_W-LIi"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK8s99KO-NJA",
        "outputId": "c5ca253e-e2a4-429b-9437-a036137a0b97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-wHqUPL5DJQ1zQmfoWz2VgRkM', created_at=1713607674, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq', finished_at=1713612238, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=['file-QdFR8GQ5baDhHlBzO237GqEG'], seed=1700530180, status='succeeded', trained_tokens=264846, training_file='file-sXjDiGxp7D7XreO01jg4nXqr', validation_file='file-E2ZWEdC8g2iX1pAOIAIS7SSh', integrations=[], user_provided_suffix='sentiment analys 3')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # First we get general information about fine-tuning. from here we will draw the fine-tune model name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VFaIvBdSB0Sw",
        "outputId": "ff4e7d16-11e1-4204-d8e4-982ce37f19e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ft:gpt-3.5-turbo-0125:personal:sentiment-analys-3:9G371mLq'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name= client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model # we pull the model name.\n",
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nNF9ZE1cCgTf"
      },
      "outputs": [],
      "source": [
        "system=\"Detect sentiment in a text.\" # The system context for prediction is the same as the system context for fine tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1_mOvgmbD55H",
        "outputId": "6e3d66ee-2e64-4f72-8bf5-46c3321dee3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I purchased this item in the gray heather color and loved it so much i wanted to buy every other color. the fabric was cottony and felt very soft and cushy against my skin, and the gray color was from the combination of black and white fibers. i ordered the light gray and the red online and could not wait for them to arrive. but the other colors were not even in the same material, but a very shiny and synthetic feeling fabric, with just a single color weave that did not have the same feel or tex'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's select a few observations from the test data and make predictions.\n",
        "display(X_test.loc[246])\n",
        "display(y_test.loc[246])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyN_Ps9pCRMw",
        "outputId": "ffe2156f-20ae-441a-bc48-05747e080af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": X_test.loc[246]}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "AFVlULVeEuKB",
        "outputId": "1d9db949-6003-4f92-bb2b-86a39c28abb3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I love this dress! the fabric and overall design are beautiful. however, the dress fit runs small, at least for me. i ordered a size 10 based on the reviews. i have another byron lars dress in a size 8 that fits well. i kept the dress because it is so pretty.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(X_test.loc[883])\n",
        "display(y_test.loc[883])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asuEDLDWEvrw",
        "outputId": "7896a0d4-923b-481a-af55-b1be1d22b19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": X_test.loc[883]}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "END OF THE PROJECT"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
